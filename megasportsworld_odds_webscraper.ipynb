{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6038dab",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5978167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "##  Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e90ab",
   "metadata": {},
   "source": [
    "### Selenium Driver Setup\n",
    "Download your browser's WebDriver first in order to webscrape using Selenium.\n",
    "\n",
    "In this notebook, the Microsoft Edge WebDriver is used. The repo also contains this driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6fad2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Change to WebDriver path\n",
    "webdriver_path = 'webdriver/msedgedriver.exe'\n",
    "\n",
    "driver = webdriver.Edge(service = Service(webdriver_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7c92d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e724b",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c5d8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Determine if string contains numbers\n",
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "## Determine if string contains text\n",
    "def text_there(s):\n",
    "    return any(i.isalpha() for i in s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d52edd",
   "metadata": {},
   "source": [
    "#### Function for webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d75d575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_odds(url, game_bool, win_only_bool):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    ----------\n",
    "    url: String containing URL to be webscraped\n",
    "    game_bool: Boolean indicating if specific games should be webscraped\n",
    "    (True if yes, False if not)\n",
    "    win_only_bool: Boolean indicating if win-only odds should be webscraped\n",
    "    (True if yes, False if not)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    ####################################################\n",
    "    ##  Get win-only bets \n",
    "    ####################################################\n",
    "    \n",
    "    if win_only_bool:\n",
    "        \n",
    "        ##  Wait for elements to load, if any\n",
    "        win_only_class = 'rank-event-section.event_path-content.event-container'\n",
    "        try:\n",
    "            WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CLASS_NAME, win_only_class)))\n",
    "            \n",
    "            ## Click all 'View all buttons'\n",
    "            view_all_class = 'show-all-rank-events.rank-event-market.event.flex-space-between'\n",
    "            view_all_lst = driver.find_elements(By.CLASS_NAME, view_all_class)\n",
    "            for button in view_all_lst:\n",
    "                button.click()\n",
    "   \n",
    "            ##  Scrape and clean data\n",
    "            win_only_markets = []\n",
    "            win_only_events = []\n",
    "            win_only_odds = []\n",
    "            win_only_market_lst = driver.find_elements(By.CLASS_NAME, win_only_class)\n",
    "            for market in win_only_market_lst:\n",
    "                market_data = market.text\n",
    "                market_data = re.sub('Order|View Less', '', market_data)\n",
    "                market_data_lst = re.split('\\\\n', market_data)\n",
    "                market_data_lst = [elem for elem in market_data_lst if elem]  ## Remove empty entries\n",
    "            \n",
    "                for i in range(len(market_data_lst)):\n",
    "                    if (i % 2 == 0) and (i != 0):\n",
    "                        win_only_events += [market_data_lst[i]]\n",
    "                        win_only_markets += [market_data_lst[0]]\n",
    "                    elif (i % 2 == 1) and (i != 1):\n",
    "                        win_only_odds += [market_data_lst[i]]\n",
    "                                    \n",
    "            ##  Create dataframe for win-only bets\n",
    "            win_only_df = pd.DataFrame(list(zip(win_only_markets, win_only_events, win_only_odds)),\n",
    "                                       columns = ['Market', 'Event/Person/Team', 'Odds'])\n",
    "        \n",
    "            ##  Add update timestamp\n",
    "            ##  Note that pd.to_datetime('now') returns UTC time, which we want to convert to Manila time\n",
    "            win_only_df['Update timestamp'] = pd.to_datetime('now')\n",
    "            win_only_df['Update timestamp'] = win_only_df['Update timestamp'].dt.tz_localize('UTC')  \n",
    "            win_only_df['Update timestamp'] = win_only_df['Update timestamp'].dt.tz_convert('Asia/Manila')\n",
    "            win_only_df['Update timestamp'] = win_only_df['Update timestamp'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "           \n",
    "        except (TimeoutException, NoSuchElementException) as e:\n",
    "            win_only_df = 'No win-only events found'\n",
    "    else:\n",
    "        win_only_df = 'Data not scraped'\n",
    "        \n",
    "    ####################################################\n",
    "    ##  Get specific game bets\n",
    "    ####################################################\n",
    "\n",
    "    if game_bool:\n",
    "        game_class = 'event_path-content.asian-event-path-component'\n",
    "        try:\n",
    "            WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CLASS_NAME, game_class)))\n",
    "        \n",
    "            ## Open separate game pages in new tabs\n",
    "            ## Note: WSM website does not accept Ctrl+Click or Shift+Click to open new tabs\n",
    "\n",
    "            all_game_df = pd.DataFrame()\n",
    "            game_link_class = 'opponent-name.bold'\n",
    "            game_link_lst = [link.get_attribute('href') for link in driver.find_elements(By.CLASS_NAME, game_link_class)]\n",
    "            if not game_link_lst:\n",
    "                game_link_lst = [link.get_attribute('href') for link in driver.find_elements(By.CLASS_NAME, 'opponent-name')]\n",
    "            \n",
    "            for link in game_link_lst:\n",
    "                driver.implicitly_wait(10)\n",
    "                driver.get(link)\n",
    "            \n",
    "                ## Wait for elements to load \n",
    "                game_market_class = 'markets-group-component' ## Contains all market data\n",
    "                game_title_class = 'event_path-title.ellipsis.rollup-title.x.collapsed'  ## Contains title for opening/closing menus\n",
    "                WebDriverWait(driver, 60).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, game_market_class)))\n",
    "                \n",
    "                ## Get game info, if game is live\n",
    "                ## Note: Info about actual start time is not in website; so current time is used as proxy \n",
    "                if 'live' in link:\n",
    "                    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CLASS_NAME, 'live-event')))\n",
    "                    game_title = driver.find_element(By.CLASS_NAME, 'live-event').text\n",
    "                    game_time = datetime.now().strftime('%Y/%m/%d %H:%M')  \n",
    "                    \n",
    "                ## Get game info if game is NOT live\n",
    "                else:\n",
    "                    game_info = driver.find_element(By.CLASS_NAME, 'event-header-description')\n",
    "                    game_info_lst = game_info.text.splitlines()\n",
    "                    game_title = game_info_lst[0]\n",
    "                    game_time = game_info_lst[1]\n",
    "        \n",
    "                    ## Convert game time into specific date and time\n",
    "                    game_time = re.sub('Starts - | -|', '', game_time)\n",
    "                    game_time = re.split(' ', game_time)\n",
    "            \n",
    "                    ## Change relative dates to actual dates\n",
    "                    if game_time[0] == 'Today':\n",
    "                        game_time[0] = datetime.today()\n",
    "                    elif game_time[0] == 'Tomorrow':\n",
    "                        game_time[0] = datetime.today() + timedelta(days = 1)\n",
    "                    else:\n",
    "                        days = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', \n",
    "                                3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'} \n",
    "                        required_day = game_time[0]\n",
    "                        current_date = datetime.today()\n",
    "                        while days[current_date.weekday()] != required_day:\n",
    "                            current_date = current_date + timedelta(days=1)\n",
    "                        game_time[0] = current_date\n",
    "                    game_time[0] = game_time[0].date()\n",
    "                \n",
    "                    ## Convert time into datetime format\n",
    "                    game_time[1] = datetime.strptime(game_time[1], '%H:%M')\n",
    "                    game_time[1] = game_time[1].time()\n",
    "            \n",
    "                    ## Combine date and time\n",
    "                    game_time = datetime.combine(game_time[0], game_time[1])\n",
    "                    game_time = game_time.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "                ## Scrape Match markets in each page\n",
    "                game_markets_title_lst = []\n",
    "                game_events_lst = []\n",
    "                game_odds_lst = []\n",
    "                game_market_lst = driver.find_elements(By.CLASS_NAME, game_market_class)\n",
    "            \n",
    "                for game_market in game_market_lst[0:5]:\n",
    "                    game_market_data = game_market.text\n",
    "                    game_market_data = re.sub('HOME AWAY', '', game_market_data)  ## Remove for Winning Margin markets\n",
    "                    game_market_data_lst = game_market_data.splitlines()\n",
    "                    game_market_data_lst = [elem for elem in game_market_data_lst if elem]  ## Remove empty entries\n",
    "\n",
    "                    for i in range(len(game_market_data_lst)):\n",
    "                        if i != 0:\n",
    "                            ## For Points-Match market, code is slightly different\n",
    "                            if game_market_data_lst[0] == 'Points - Match':\n",
    "                                if text_there(game_market_data_lst[i]):\n",
    "                                    if 'Over' in game_market_data_lst[i]:\n",
    "                                        game_events_lst += [game_market_data_lst[i-1] + ' ' + game_market_data_lst[i]]\n",
    "                                        game_markets_title_lst += [game_market_data_lst[0]]\n",
    "                                    elif 'Under' in game_market_data_lst[i]: \n",
    "                                        game_events_lst += [game_market_data_lst[i-3] + ' ' + game_market_data_lst[i]]\n",
    "                                        game_markets_title_lst += [game_market_data_lst[0]]\n",
    "                                    \n",
    "                                if num_there(game_market_data_lst[i]) and not text_there(game_market_data_lst[i]):\n",
    "                                    if i + 1 < len(game_market_data_lst) and text_there(game_market_data_lst[i+1]):\n",
    "                                        game_odds_lst += [game_market_data_lst[i]]\n",
    "                                    else:\n",
    "                                        game_odds_lst += [game_market_data_lst[i]] \n",
    "                            \n",
    "                            ## Other markets follow roughly the same format\n",
    "                            else:\n",
    "                                if text_there(game_market_data_lst[i]):\n",
    "                                    if i + 2 < len(game_market_data_lst) and not text_there(game_market_data_lst[i+2]): \n",
    "                                        game_events_lst += [game_market_data_lst[i] + ' ' + game_market_data_lst[i+1]]\n",
    "                                        game_markets_title_lst += [game_market_data_lst[0]]\n",
    "                                    else:\n",
    "                                        game_events_lst += [game_market_data_lst[i]]\n",
    "                                        game_markets_title_lst += [game_market_data_lst[0]]\n",
    "                    \n",
    "                                if num_there(game_market_data_lst[i]):\n",
    "                                    if i + 1 < len(game_market_data_lst) and text_there(game_market_data_lst[i+1]):\n",
    "                                        game_odds_lst += [game_market_data_lst[i]]\n",
    "                                    elif i + 1 == len(game_market_data_lst):\n",
    "                                        game_odds_lst += [game_market_data_lst[i]]  ## Last element will always be bet odds\n",
    "\n",
    "                ## Create list of game titles and time\n",
    "                game_title_lst = sorted([game_title] * len(game_events_lst))\n",
    "                game_time_lst = sorted([game_time] * len(game_events_lst))\n",
    "            \n",
    "                ## Create dataframe for each game\n",
    "                game_df = pd.DataFrame(list(zip(game_title_lst, game_time_lst, game_markets_title_lst, \n",
    "                                                game_events_lst, game_odds_lst)),\n",
    "                                       columns = ['Game', 'Datetime', 'Market', 'Event/Person/Team', 'Odds'])\n",
    "                \n",
    "                ## Append to dataframe for all games\n",
    "                all_game_df = pd.concat([all_game_df, game_df], ignore_index = True)\n",
    "                driver.implicitly_wait(10)\n",
    "                    \n",
    "            ##  Add update timestamp\n",
    "            ##  Note that pd.to_datetime('now') returns UTC time, which we want to convert to Manila time\n",
    "            all_game_df['Update timestamp'] = pd.to_datetime('now')\n",
    "            all_game_df['Update timestamp'] = all_game_df['Update timestamp'].dt.tz_localize('UTC')  \n",
    "            all_game_df['Update timestamp'] = all_game_df['Update timestamp'].dt.tz_convert('Asia/Manila')\n",
    "            all_game_df['Update timestamp'] = all_game_df['Update timestamp'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "        except (TimeoutException, NoSuchElementException) as e:\n",
    "            win_only_df = 'No games found'\n",
    "            \n",
    "    else:\n",
    "        all_game_df = 'Data not scraped'\n",
    "            \n",
    "    return win_only_df, all_game_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71117ae4",
   "metadata": {},
   "source": [
    "### Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe00d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List URLs to scrape\n",
    "msw_url_lst = ['https://sports.msw.ph/en/sports/227-basketball/75477-philippines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f28a033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicate whether to scrape markets or not\n",
    "## Win-only: Markets that do not have separate pages\n",
    "## Game: Markets with separate pages \n",
    "scrape_win_only = True\n",
    "scrape_game = True\n",
    "\n",
    "## Initialize dataframes\n",
    "if scrape_win_only:\n",
    "    win_only_df = pd.DataFrame()\n",
    "if scrape_game:\n",
    "    game_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65631183",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in msw_url_lst:\n",
    "    [win, game] = get_odds(url, scrape_win_only, scrape_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4bd7557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Webscrape URLs in list\n",
    "for url in msw_url_lst:\n",
    "    [win, game] = get_odds(url, scrape_win_only, scrape_game)\n",
    "    \n",
    "    if scrape_win_only and type(win) != str:\n",
    "        win_only_df = pd.concat([win_only_df, win])\n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "    if scrape_game and type(game) != str:\n",
    "        game_df = pd.concat([game_df, game])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfced5",
   "metadata": {},
   "source": [
    "### Saving data\n",
    "Dataframes can either be saved as new files, or be appended to an already existing file.  \n",
    "\n",
    "Make sure to comment lines not used, especially when running this script at regular intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb3faa",
   "metadata": {},
   "source": [
    "#### Save as new file/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b852fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change paths as needed\n",
    "#win_only_path = 'data/pba_wo_mid2022.csv'\n",
    "#game_path = 'data/pba_game_mid2022.csv'\n",
    "\n",
    "## Save as CSVs\n",
    "#win_only_df.to_csv(f'{win_only_path}', index = False)\n",
    "#game_df.to_csv(f'{game_path}', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2997d20",
   "metadata": {},
   "source": [
    "#### Append to existing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbf6e6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Change paths as needed\n",
    "# win_only_hist_path = 'data/pba_wo_mid2022.csv'\n",
    "game_hist_path = 'data/pba_game_mid2022.csv'\n",
    "\n",
    "## Load existing CSVs\n",
    "# win_only_hist = pd.read_csv(f'{win_only_hist_path}', index_col = None)\n",
    "game_hist = pd.read_csv(f'{game_hist_path}', index_col = None)\n",
    "\n",
    "## Append new data\n",
    "# win_only_hist = pd.concat([win_only_hist, win_only_df])\n",
    "game_hist = pd.concat([game_hist, game_df])\n",
    "\n",
    "## Save updated files as CSVs\n",
    "# win_only_hist.to_csv(f'{win_only_hist_path}', index = False)\n",
    "game_hist.to_csv(f'{game_hist_path}', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e57c398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022/06/19 18:52'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y/%m/%d %H:%M')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
